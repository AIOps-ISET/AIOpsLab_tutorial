# 知识图谱研究方向

* 参考知识图谱研究综述论文A Survey on Knowledge Graphs: Representation, Acquisition and Applications整理。

​ [下载地址](https://arxiv.org/abs/2002.00388)

* 推荐关注一位博客园博主：胡萝不青菜（[地址](https://www.cnblogs.com/fengwenying/)），该博主对翻译模型、线性/双线性模型、神经网络模型有系统性的总结和介绍。

> 注：后文划分的模型分类不一定准确，但都是知识图谱领域的经典模型

## （一）知识表示学习相关

* 知识表示学习(knowledge graph representation learning, KRL)，又称图嵌入(knowledge graph embedding, KGE), 多关系学习(multi-relation learning), 统计关系学习(statistical relational learning)，主要思想是利用实体和关系的语义信息，将实体和关系映射成低维的向量表示。它是知识图谱研究的核心也是基础，研究主要分以下四个方面：

### 1. 表示空间

* 表示空间(representation space)指的是关系和实体将要被映射到的空间。表示学习的关键就是学习得到实体和关系的低维嵌入。现有的研究主要使用实值的point-wise空间（图 a），包括向量、矩阵和张量空间，也有使用其他类型的空间例如复杂向量空间（图 b）、高斯空间（图 c）和Manifold space（图 d）。

![image-20220518132331004](broken-reference)

![image-20220518132341270](broken-reference)

![image-20220518132355663](broken-reference)

![image-20220518132413192](broken-reference)

#### （1）point-wise空间

* point-wise欧式空间广泛用于实体和关系的表示，用于将关系嵌入映射到向量或矩阵空间或者捕获关系的交互信息。是使用最多的一个空间。
* 该空间以**翻译模型TransE**和其**变种模型TransX系列**为代表，遵循h(头实体) + r(关系) ≈ t(尾实体) 的原则。
* 模型论文名称及出处：

① TransE，NIPS 2013，Translating embeddings for modeling multi-relational data

​ [下载地址](https://proceedings.neurips.cc/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html)

② TransH，AAAI 2014，Knowledge graph embedding by translating on hyperplanes

​ [下载地址](https://ojs.aaai.org/index.php/AAAI/article/view/8870)

③ TransD，ACL 2015，Knowledge graph embedding via dynamic mapping matrix

​ [下载地址](https://www.semanticscholar.org/paper/Knowledge-Graph-Embedding-via-Dynamic-Mapping-Ji-He/18bd7cd489874ed9976b4f87a6a558f9533316e0?p2df)

④ TransA，arXiv 2015，An adaptive approach for knowledge graph embedding

​ [下载地址](https://arxiv.org/pdf/1509.05490.pdf)

⑤ TransR，AAAI 2015，Learning Entity and Relation Embeddings for Knowledge Graph Completion

​ [下载地址](http://nlp.csai.tsinghua.edu.cn/\~lyk/publications/aaai2015\_transr.pdf)

#### （2）复杂向量空间

* 复杂向量空间（Complex Vector Space）不将实体和关系表示在实值的空间中，而是表示在一个复杂空间中。
* 该空间的代表模型有**ComplEx**、**RotatE**以及**QuatE**。
* 模型论文名称及出处：

① ComplEx，Complex Embeddings for Simple Link Predictio

​ [下载地址](http://proceedings.mlr.press/v48/trouillon16.pdf)

② RotatE，ICLR 2019，RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space

​ [下载地址](https://arxiv.org/abs/1902.10197)

③ QuatE，NIPS 2019，Quaternion Knowledge Graph Embeddings

​ [下载地址](https://proceedings.neurips.cc/paper/2019/file/d961e9f236177d65d21100592edb0769-Paper.pdf)

#### （3）高斯空间

* 高斯空间（Gaussian space）受高斯词嵌入启发，基于密度的嵌入模型KG2E引入了高斯分布来处理确定的/不确定的实体和关系。类似地，TransG使用高斯分布表示实体，使用混合的高斯分布表示关系嵌入。
* 该空间的代表模型有**KG2E**、**TransG**。
* 模型论文名称及出处：

① KG2E，CIKM 2015，Learning to represent knowledge graphs with gaussian embedding

​ [下载地址](https://www.semanticscholar.org/paper/Learning-to-Represent-Knowledge-Graphs-with-He-Liu/02e2059c328bd9fad4e676266435199663bed804)

② TransG，arxiv 2015，A Generative Mixture Model for Knowledge Graph Embedding

​ [下载地址](https://arxiv.org/abs/1509.05488)

#### （4）流形空间

* 流形空间（mainfold space）是一个拓扑空间，可以定义成具有邻域的点的集合。之前的point-wise建模是不适定的代数系统，其中计分方程的数量远远超过实体和关系的数量。即使在某些子空间的投影方法中，嵌入也受到严格的几何形式的限制。因此为处理这一问题MainfoldE将point-wise嵌入扩展成mainfold-based嵌入。
* 该空间代表模型有**ManifoldE**、**TorusE**和**DihEdral**。
* 模型论文名称及出处：

① ManifoldE，IJCAI 2016，From One Point to a Manifold: Knowledge Graph Embedding for Precise Link Prediction

​ [下载地址](https://www.ijcai.org/Proceedings/16/Papers/190.pdf)

② TorusE，AAAI 2018，TorusE: Knowledge Graph Embedding on a Lie Group

​ [下载地址](https://arxiv.org/abs/1711.05435)

③ DihEdral， ACL, 2019，Relation embedding with dihedral group in knowledge graph

​ [下载地址](https://aclanthology.org/P19-1026.pdf)

### 2. 评分函数

* 评分函数（scoring function）用于度量事实的可信性，在基于能量的学习框架中也称为能量函数。评分函数有两种典型类型，基于距离（如图a）和基于相似性（如图b）的函数。基于距离的评分函数通过计头尾算实体之间的距离来衡量事实的可信性，其中使用较多的是带有h(头实体) + r(关系) ≈ t(尾实体)关系的翻译。基于语义相似度的评分方法是通过语义匹配来衡量事实的可信性，通常采用乘法矩阵公式。

![image-20220518142543038](broken-reference)

![image-20220518142550059](broken-reference)

* 使用基于距离的评分函数模型：**TranE**、**TransH**、**TransR**、**TransD**、**TransA**、**KG2E**、**ManifoldE**
* 使用基于距离的评分函数模型：**SME**、**DisuMult**、**HolE**、**CrossE**、**ANALOGY**、**TorusE**
* 模型论文名称及出处：

① SME， Machine Learning 2014， A Semantic Matching Energy Function for Learning with Multi-relational Data

​ [下载地址](https://link.springer.com/content/pdf/10.1007%2Fs10994-013-5363-6.pdf)

② DisuMult，ICLR 2015，Embedding entities and relations for learning and inference in knowledge bases

​ [下载地址](https://arxiv.org/abs/1412.6575)

③ HolE，AAAI 2016，Holographic Embeddings of Knowledge Graphs

​ [下载地址](https://arxiv.org/abs/1510.04935)

④ CrossE，WSDM 2019，Interaction Embeddings for Prediction and Explanation in Knowledge Graphs

​ [下载地址](https://arxiv.org/abs/1903.04750)

⑤ ANALOGY， ICML 2017 ，Analogical Inference for Multi-relational Embeddings

​ [下载地址](https://arxiv.org/abs/1705.02426)

### 3. 编码模型

* 编码模型（encoding models）主要包括线性/双线性模型(Linear/Bilinear Models)、因式分解模型(Factorization Models)和神经网络(Neural Networks)，目的是对实体和关系进行编码的模型。

#### （1）线性/双线性模型

* 线性模型(Linear/Bilinear Models)通过将头部实体投射到接近尾部实体的表示空间中，将关系表示为线性/双线性映射。
* 使用线性/双线性的方法模型：**SE**, **SME**, **DistMult**, **ComplEx**, **ANALOGY**。
* 模型论文名称及出处：

① SE，CVPR 2018，Squeeze-and-Excitation Networks

​ [下载地址](https://arxiv.org/abs/1709.01507)

#### （2）因式分解模型

* 因式分解模型(Factorization Models)将KRL问题建模成了3个张量的分解。目的是将关系数据分解为低秩矩阵进行表示学习。
* 使用因式分解方法模型：**RESCAL**、**LFM**、**TuckER**
* 模型论文名称及出处：

① RESCAL，ICML 2011，A Three-Way Model for Collective Learning on Multi-Relational Data

​ [下载地址](https://icml.cc/2011/papers/438\_icmlpaper.pdf)

② LFM，NIPS 2012，A latent factor model for highly multi-relational data

​ [下载地址](https://papers.nips.cc/paper/2012/file/0a1bf96b7165e962e90cb14648c9462d-Paper.pdf)

③ TuckER，Machine Learning 2019，TuckER: Tensor Factorization for Knowledge Graph Completion

​ [下载地址](https://arxiv.org/abs/1901.09590)

#### （3）神经网络模型

* 神经网络模型用非线性神经激活函数和更复杂的网络结构来编码实体关系数据。如MLP、CNN、RNN、Transformer、GNN等网络结构，如下图。

![preview](broken-reference)

* 使用神经网络的方法模型：**SME**、**ConvE**、**HypER**、**R-GCN**、**SACN** 、**KBGAT**、**ConvKB**
* 模型论文名称及出处：

① ConvE，AAAI 2018， Convolutional 2D Knowledge Graph Embeddings

​ [下载地址](https://arxiv.org/abs/1707.01476)

② HypER，IEEE 2014，Hyperspectral Image Classification Through Bilayer Graph-Based Learning

​ [下载地址](https://www.semanticscholar.org/paper/Hyperspectral-Image-Classification-Through-Bilayer-Gao-Ji/e65d9c0ec227fede74332cefaf9a41d41aae6b88)

③ R-GCN，ESWC(CCF-C) 2018，Modeling Relational Data with Graph Convolutional Networks

​ [下载地址](https://arxiv.org/abs/1703.06103)

④ SACN，AAAI 2019，End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion

​ [下载地址](https://arxiv.org/abs/1811.04441)

⑤ KBGAT，ACL 2019，Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs

​ [下载地址](https://arxiv.org/abs/1906.01195)

⑥ ConvKB，NAACL 2018 ，A Novel Embedding Model for Knowledge Base Completion Based on Convolutional Neural Network

​ [下载地址](https://arxiv.org/abs/1712.02121)

### 4. 辅助信息

* 辅助信息（auxiliary information）为了促进更有效的知识表示，多模态嵌入将外部信息如文本描述、类型约束、关系路径和可视化信息与知识图谱本身结合在一起。

#### （1）文本描述

* KG中有文本描述的实体定义为D = < w1 , w2 , . . . , wn > ，作为语义信息的补充。
* 使用文本描述的KRL任务的挑战是将结构的知识和无结构的文本信息嵌入到同一个空间中。
* 现有研究进展：

​ 1> Wang等人提出了两个对齐的模型，通过引入实体名字和Wikipedia的锚（anchors），来对齐实体空间和单词空间。

​ 2> DKRL是TransE的扩展，该模型通过卷积编码器直接从实体描述中学习到了表示；

​ 3> SSP通过将三元组和文本描述投影到一个语义子空间，建模了三元组和文本描述间的强关联。

* 模型论文名称及出处：

① DKRL，AAAI 2016，DKRL: Representation Learning of Knowledge Graphs with Entity Descriptions

​ [下载地址](http://nlp.csai.tsinghua.edu.cn/\~xrb/publications/AAAI-16\_description.pdf)

② SSP，AAAI 2017，SSP: Semantic Space Projection for Knowledge Graph Embedding with Text Descriptions

[下载地址](https://www.aaai.org/Conferences/AAAI/2017/PreliminaryPapers/14-XiaoH-14306.pdf)

#### （2）类型描述

* 使用层级的分类或者类型来表示实体，关系也可以有不同的语义类型。
* 现有研究进展：

​ 1> SSE合并了实体的语义类别，在语义空间中平滑地嵌入属于同一类别的实体。

​ 2> TKRL提出了实体投影矩阵的类型编码模型，以捕获类型层次结构。

​ 3> KR-EAR模型注意到了一些关系暗示着实体的属性，该模型将关系类型分类成属性和关系，并建模实体描述间的关联。

​ 4> Zhang等人使用关系簇、关系和子关系的层次关系结构，扩展了现有的嵌入方法。

* 模型论文名称及出处：

​ ① TKRL，IJCAI 2016，Representation learning of knowledge graphs with hierarchical types

​ [下载地址](https://www.semanticscholar.org/paper/Representation-Learning-of-Knowledge-Graphs-with-Xie-Liu/17a1e5d78bffb17979ac55aa792698727fe25a21)

​ ② KR-EAR，IJCAI 2016，Knowledge Representation Learning with Entities, Attributes and Relations

​ [下载地址](https://www.ijcai.org/Proceedings/16/Papers/407.pdf)

#### （3）视觉信息

* 视觉信息，例如实体的图片，可以丰富KRL。
* 现有研究进展：

​ 1> IKRL模型包含了跨媒体的基于结构和基于图片的表示，将图片编码到实体空间，并且遵循translation规则。跨媒体的表示需要保证基于结构的和基于图片的表示在同一个表示空间中。

### 5. 总结

* 在提出新的KRL模型要回答以下4个问题：

​ 1）应该选择什么样的表示空间；

​ 2）如何衡量特定空间中的三元组的合理性；

​ 3）选择什么样的编码模型对关系交互进行建模；

​ 4）是否要利用辅助信息。

## （二）知识获取相关

* 知识获取的目的是从非结构化文本中构造知识图谱，补全已有的知识图谱，发现识别实体和关系。知识获取的主要任务包括**关系抽取**、**知识图谱补全（KGC）和其他的面向实体获取的任务，例如实体识别**和**实体对齐**。

### 1. 知识图谱补全

* 知识图谱补全（KGC）基于知识图谱不完备的问题，为知识图谱增加新的三元组。典型的子任务包括**链路预测**、**实体预测**和**关系预测**。对KGC的初步研究主要集中在学习低维嵌入的方式用于三元组预测，即**基于嵌入的方法(Embedding-based Models)**。然而，基于嵌入的补全方法大多数都没有捕捉到多步的关系。因此，最近的工作转向探索多步的关系路径和整合逻辑规则，分别称为**基于关系路径推理(Relation Path Reasoning)和基于规则的推理(Rule-based Reasoning)**。除此之外，\*\*基于强化学习(RL-based Path Finding)和元关系学习(Meta Relational Learning)\*\*的方法也有研究。

#### （1）基于嵌入的方法

* 前面提到的KRL方法，例如**TransE**、**TransH**、**TransR**、**HolE**和**R-GCN**，以及联合学习方法，例如**DKRL**，都可以用于KGC中。

#### （2）关系路径推理

* 实体和关系的嵌入学习虽然在一些任务中取得了不错的效果，但是不能对复杂的关系路径建模。关系路径推理利用了图结构中的路径信息。
* 现有研究进展：

​ 1）随机游走推断已经被广泛研究，例如Path-Ranking算法（PRA）在路径限制额组合下选择了关系路径，并且进行了极大似然分类。

​ 2）为了改进路径搜索，Gardner等人通过结合文本内容，在随机游走中引入了向量空间相似性的启发式方法，同时缓解了PRA中的特征稀疏性问题。

​ 3）Neelakantan等人提出了RNN模型，通过递归地应用组合性来组合关系路径的内涵。

​ 4）Chain-of-Reasoning是一种支持multiple reasons的神经注意力机制，它表示了跨所有关系、实体和文本的逻辑组合。

​ 5）最近，DIVA提出了统一的变分推断框架，该框架将多条推理视为两个子过程：1）路径的发现，底层路径推断的先验分布；2）路径推理，用于链接分类的似然。

#### （3）基于规则的推理

* 一个规则由head和body组成，形式化为head ← body 。其中head是一个原子（atom），例如有着可变subject和/或objects的事实；body可以是原子的集合。
* 现有更多的研究关注于将逻辑规则整合到嵌入中，以提高模型的推理能力，例如使用联合学习和迭代训练用于合并一阶逻辑规则。可以使用规则挖掘工具（例如 AMIE）来抽取出逻辑规则。现有研究进展有：

​ 1）KALE提出了统一的联合模型，定义了兼容三元组和逻辑规则嵌入的t-范数（t-norm）模糊逻辑连接词。定义了逻辑合取、析取和否定三种组合，构成complex formula的真值。图 7a展示了简单的一阶Horn clause推断。

​ 2）RUGE提出迭代的模型，使用soft rules从无标注的三元组进行soft的标签预测，从有标签的三元组进行embedding rectification。

​ 3）IterE提出递归的训练策略，有3个部分：嵌入学习；axiom induction；axiom injection。

* 神经模型和符号模型的结合同样吸引了研究者的注意力，其可使用端到端的方式实现基于规则的推理。现有研究进展有：

​ 1）Neural Theorem Provers (NTP) 学习到了用于多条推理的逻辑规则，利用了radial basis function kernel在向量空间上进行可微计算。

​ 2）NeuralLP实现了在归纳式的逻辑编程（inductive logic programming）中使用基于梯度的优化，其中的神经控制系统使用了集成注意力机制和辅助记忆。

​ 3）pLogicNet提出了概率逻辑神经网络，如图 7b所示，铜鼓结合Markov逻辑网络和KRL方法的优点，利用了一阶逻辑并学习到了有效的嵌入，同时处理了逻辑规则的不确定性。

​ 4）ExpressGNN\[4]对graph networks和嵌入进行微调，对pLogicNet进行了泛化，并实现了更有效的逻辑推理。

### 2. 实体发现

* 实体发现这里主要包含几个任务的细分，即**实体识别**、**实体消歧**、**实体对齐**、**实体类型**。
* **实体识别**是NLP的基础任务，主要的模型是**LSTM**、**CRF**、**MGNER**等。
* **实体类型**包括粗粒度和细粒度类型，而后者使用树形结构类型类别，通常被视为多类别和多标签分类，典型的模型是**PLE**。
* **实体消歧**或**实体链接**是将实体与知识图谱中相应的实体进行链接进而统一的任务，代表模型是**DSRM**、**EDKate**等。上述任务涉及到从文本或单个知识图谱中发现实体，而实体对齐(EA)旨在融合异类知识图谱之间的知识。
* 模型论文名称及出处：

① LSTM，IEEE 1997，Long Short-Term Memory

​ [下载地址](https://pubmed.ncbi.nlm.nih.gov/9377276/)

② CRF，ACM, 2001，Conditional R andom Fields: Probabilistic Models for Segmenting and Labeling Sequence Data

​ [下载地址](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162\&context=cis\_papers)

③ LSTM-CRF，NAACL 2016,Neural architectures for named entity recognition

​ [下载地址](https://arxiv.org/abs/1603.01360)

④ BiLSTM-CRF，Bidirectional LSTM-CRF Models for Sequence Tagging

​ [下载地址](https://arxiv.org/pdf/1508.01991v1.pdf)

⑤ MGNER，ACL 2019，Multi-Grained Named Entity Recognition

​ [下载地址](https://arxiv.org/abs/1906.08449)

⑥ PLE，ACM 2020，Progressive Layered Extraction (PLE): A Novel Multi-Task Learning (MTL) Model for Personalized Recommendations

​ [下载地址](https://dl.acm.org/doi/abs/10.1145/3383313.3412236)

### 3. 关系抽取

* 关系抽取是从纯文本中抽取未知的关系事实并将其加入到知识图谱中，是自动构建大规模知识图谱的关键。目前来说，都在采用神经网络进行关系抽取的研究，如下图。

![image-20220518162555464](broken-reference)

* 相关研究论文名称：

​ ① Constructing biological knowledge bases by extracting information from text sources

​ ② Discovering correlations between sparse features in distant supervision for relation extraction

​ ③ Relation extraction with multi-instance multi-label convolutional neural networks

​ ④ Incorporating relation paths in neural relation extraction

## （三）时序知识图谱相关

* 时序知识图谱是当下研究的热点。目前对知识图谱的研究主要集中在事实不随时间变化的静态知识图谱上，而对知识图谱的时态动力学研究较少。然而，时间信息是非常重要的，因为结构化的知识只在特定的时间段内保持，而事实的演变遵循时间序列。最近的研究开始将时态信息引入KRL和KGC中，称为时序知识图谱。人们已经为同时学习时间嵌入和关系嵌入做出了努力。动态网络嵌入的相关模型也启发了时序知识图的嵌入。例如，同时捕获时间-拓扑结构并学习时间-特征交互的\*\*时序图注意网络(TGA-T)\*\*可能有助于为知识图保留时态感知关系。

### 1. 时序信息嵌入

* 在时间感知嵌入中，通过将三元组扩展为时间四元组(h，r，t，τ)来考虑时间信息，其中τ 提供关于事实何时存在的附加时间信息。
* 现有研究进展：

​ 1）Leblay和Chekol研究了带时间注释的三元组上的时间范围预测，并简单地扩展了现有的嵌入方法。

​ 2）Ma等人推广了已有的静态嵌入方法，提出了用时间戳嵌入代替Tucker的共享权向量的**CONT**方法。

​ 3）Garc‘ıa-Dur’an等人提出了级联谓词令牌序列和时态令牌序列，并对级联后的时间感知谓词序列进行了LSTM编码。

​ 4）Liu等人\[建议使用上下文选择来捕获有用的上下文，并测量与所选上下文的时间一致性。通过将时态KGC表示为四阶张量补全。

​ 5）Lacroix等人提出了扩展复分解的TComplEx，并引入了加权正则化子。

* 相关研究论文名称：

​ ① Deriving validity time in knowledge graph

​ ② Embedding models for episodic knowledge graphs

​ ③ Learning sequence encoders for temporal knowledge graph completion

​ ④ Context-aware temporal knowledge graph embedding

​ ⑤ Tensor decompositions for temporal knowledge base completion

### 2. 实体动力学

* 现实世界的事件改变了实体的状态，从而影响了相应的关系。
* 现有研究进展：

​ 1）为了改进时间范围推理，上下文时间轮廓模型将时间范围问题描述为状态变化检测，并利用上下文来学习状态和状态变化向量；

​ 2）受到历时单词嵌入的启发，Goel等人将实体和时间戳作为实体嵌入函数的输入，保留实体在任意时间点的时态感知特征；

​ 3）KNOW-EVERVE是一个深度进化的知识网络，它研究实体的知识进化现象及其进化关系。利用多变量时点过程对FACTS的发生进行建模，并开发了一种新的递归网络来学习非线性时间演化的表示；

​ 4）为了捕获节点之间的交互，RE-Net通过基于RNN的事件编码器和邻域聚合器对事件序列进行建模。具体而言，RNN用于捕获时态实体交互，邻域聚合器聚合并发交互。

* 相关研究论文名称：

​ ① CTPs: Contextual temporal profiles for time scoping facts using state change detection

​ ② Diachronic embedding for temporal knowledge graph completion

​ ③ Know-evolve: Deep temporal reasoning for dynamic knowledge graphs

​ ④ Recurrent event network for reasoning over temporal knowledge graphs

### 3. 时序关系依赖

* 在时间线之后的关系链中存在时间依赖，如wasBornIn → graduateFrom → workAt → diedIn
* 现有研究进展：

​ 1）Jiang等人提出了时间感知嵌入，这是一种结合时态正则化的联合学习框架，以融合时序和一致性信息。

* 相关研究论文名称：

​ ① Towards time-aware knowledge graph completion

​ ② Encoding temporal information for time-aware link prediction

### 4. 时序逻辑推理

* 现有研究进展：

​ 1）Chekol等人研究了马尔可夫逻辑网络和概率软逻辑在不确定时间知识图上的推理问题；

​ 2）RLvLR-Stream考虑了时间闭合路径规则，并从知识图流中学习规则的结构以进行推理。

* 相关研究论文名称：

​ ① Marrying uncertainty and time in knowledge graphs

​ ② An embedding-based approach to rule learning in knowledge graphs

## （四）知识图谱应用相关

* 丰富的结构化知识对人工智能应用程序很有用。然而，如何将这些符号知识整合到现实世界应用的计算框架中仍然是一个挑战。知识图的应用包括两个方面：1)知识图内的应用，如链接预测和命名实体识别；2)知识图外的应用，包括关系提取和更多的下游知识感知应用，如问答和推荐系统。

### 1. 语义表征学习(Language Representation Learning)

* 通过自我监督的语言模型预训练进行语言表征学习已经成为许多自然语言处理系统的重要组成部分。传统的语言建模没有利用文本语料库中频繁观察到的实体的事实知识。如何将知识整合到语言表达中，越来越受到人们的关注。
* 典型模型：**KGLM**、**K-BERT** 等
* 模型论文名称及出处：

① KGLM，Computation and Language 2019，Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling

​ [下载地址](https://arxiv.org/abs/1906.07241)

② K-BERT，Computation and Language 2019，K-BERT: Enabling Language Representation with Knowledge Graph

​ [下载地址](https://arxiv.org/abs/1909.07606v1)

### 2. 问答系统(Question Answering)

* 基于知识图谱的问答（KG-QA）用知识图谱中的事实回答自然语言问题。基于神经网络的方法表示分布式语义空间中的问题和答案，有些方法还进行符号知识注入以进行常识推理。
* 现有研究进展：

​ 1）Single-fact QA：以知识图谱为外部知识源，simple factoid QA或single-fact QA是回答一个涉及单个知识图谱事实的简单问题。

​ 2）Dai等人：提出了一种条件聚焦神经网络，配备聚焦修剪以减少搜索空间。

​ 3）BAMnet：使用双向注意机制对问题和知识图谱之间的双向交互进行建模。尽管深度学习技术在KG-QA中得到了广泛应用，但它们不可避免地增加了模型的复杂性。

​ 4）Mohammed等人：通过评估有和没有神经网络的简单KG-QA，发现复杂的深度模型（如LSTM和GRU等启发式算法）达到了最先进的水平，非神经模型也获得了相当好的性能。

​ 5）多跳推理（Multi-hop Reasoning）：处理复杂的多跳关系需要更专门的设计才能进行多跳常识推理。结构化知识提供了信息丰富的常识，这促进了最近关于多跳推理的符号空间和语义空间之间的常识知识融合的研究。

​ 6）Bauer等人：提出了多跳双向注意力和指针生成器（pointer-generator）解码器，用于有效的多跳推理和连贯的答案生成，利用来自ConceptNet的relational path selection和selectively-gated注意力注入的外部常识知识。

​ 7）Variational Reasoning Network(VRN)：使用reasoning-graph嵌入进行多跳逻辑推理，同时处理主题实体识别中的不确定性。

​ 8）KagNet：执行concept recognition以从ConceptNet构建模式图，并通过GCN、LSTM和hierarchical path-based attention学习基于路径的关系表示。

​ 9）CogQA：结合了implicit extraction和explicit reasoning，提出了一种基于BERT和GNN的认知图模型，用于多跳QA。

* 相关论文名称：

​ ① CFO: Conditional focused neural question answering with large-scale knowledge bases

​ ② Bidirectional attentive memory networks for question answering over knowledge bases

​ ③ Strong baselines for simple question answering over knowledge graphs with and without neural networks

​ ④ Commonsense for generative multi-hop question answering tasks

​ ⑤ V ariational reasoning for question answering with knowledge graph

​ ⑥ KagNet: Knowledge-aware graph networks for commonsense reasoning

​ ⑦ Cognitive graph for multi-hop reading comprehension at scale

### 3. 推荐系统

* 将知识图谱集成为外部信息，使推荐系统具备常识推理能力，具有解决稀疏问题和冷启动问题的潜力。通过注入实体、关系和属性等知识图谱的辅助信息，许多方法致力于使用基于嵌入的正则化模块以改进推荐效果。
* 现有研究进展：

​ 1）collaborative CKE：通过平移KGE模型和堆叠自动编码器联合训练KGE、文本信息和视觉内容。

​ 2）DKN：注意到时间敏感和主题敏感的新闻文章由大量密集的实体和常识组成，通过知识感知CNN模型将知识图谱与多通道word-entity-aligned文本输入相结合。但是，DKN不能以端到端的方式进行训练，因为它需要提前学习实体嵌入。

​ 3）MKR：为了实现端到端训练，通过共享潜在特征和建模高阶项目-实体交互，将多任务知识图谱表示和推荐相关联。

​ 4）KPRN：虽然其他工作考虑了知识图谱的关系路径和结构，但KPRN将用户和项目之间的交互视为知识图谱中的实体关系路径，并使用LSTM对路径进行偏好推断以捕获顺序依赖关系。

​ 5）PGPR：在基于知识图谱的user-item交互上执行reinforcement policy-guided的路径推理。

​ 6）KGAT：在entity-relation和user-item图的协作知识图谱上应用图注意力网络，通过嵌入传播和基于注意力的聚合对高阶连接进行编码。

* 相关论文名称：

​ ① CKE，Collaborative knowledge base embedding for recommender systems

​ ② DKN，DKN: Deep knowledge-aware network for news recommendation

​ ③ MKR，Multi-task feature learning for knowledge graph enhanced recommendation

​ ④ KPRN，Explainable reasoning over knowledge graphs for recommendation

​ ⑤ PGPR，Reinforcement knowledge graph reasoning for explainable recommendation

​ ⑥ KGAT，KGA T: Knowledge graph attention network for recommendation

## （五）未来研究方向

1. 更加复杂的推理
2. 统一框架展开研究
3. 可解释性的研究（神经网络老生常谈的问题）
4. 可扩展性的研究（对于大规模的知识图谱十分必要）
5. 知识的信息聚合
6. 图谱的自动构建
